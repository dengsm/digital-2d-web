'use client'

import { useState, useRef, useEffect, memo } from 'react';
import { StopCircleIcon, MicrophoneIcon, PaperAirplaneIcon } from '@heroicons/react/24/solid';
import { useSentioAsrStore, useChatRecordStore, useSentioAgentStore, useSentioTtsStore, useSentioBasicStore } from '@/lib/store/sentio';
import { Input, Button, Spinner, addToast, Tooltip, Modal, ModalContent, ModalHeader, ModalBody } from '@heroui/react';
import { CHAT_ROLE } from '@/lib/protocol';
import { api_asr_infer_file, api_agent_stream, api_tts_infer } from '@/lib/api/server';
import { Live2dManager } from '@/lib/live2d/live2dManager';
import { SENTIO_TTS_PUNC, SENTIO_TTS_SENTENCE_LENGTH_MIN } from '@/lib/constants';
import { base64ToArrayBuffer, ttsTextPreprocess } from '@/lib/func';
import { convertMp3ArrayBufferToWavArrayBuffer } from '@/lib/utils/audio';
import { createASRWebsocketClient, WS_RECV_ACTION_TYPE, WS_SEND_ACTION_TYPE } from '@/lib/api/websocket';
import { useTranslations } from 'next-intl';
import { convertToMp3, convertFloat32ArrayToMp3, AudioRecoder } from '@/lib/utils/audio';
import Recorder from 'js-audio-recorder';
import { useMicVAD } from "@ricky0123/vad-react"
import { useChatWithAgent, useAudioTimer } from '../../hooks/chat';
import { getSrcPath } from '@/lib/path';
import clsx from 'clsx';
import html2canvas from 'html2canvas';

let micRecoder: Recorder | null = null;


export const ChatInput = memo(({ 
    postProcess
}: {
    postProcess?: (conversation_id: string, message_id: string, think: string, content: string) => void
   
}) => {
    const t = useTranslations('Products.sentio');
    const [message, setMessage] = useState("");
    const [startMicRecord, setStartMicRecord] = useState(false);
    const [startAsrConvert, setStartAsrConvert] = useState(false);
    const [screenshotDataUrl, setScreenshotDataUrl] = useState<string | null>(null);
    const [showScreenshotPreview, setShowScreenshotPreview] = useState(false);
    const { enable: enableASR, engine: asrEngine, settings: asrSettings } = useSentioAsrStore();
    const { addChatRecord, updateLastRecord } = useChatRecordStore();
    const { engine: agentEngine, settings: agentSettings } = useSentioAgentStore();
    const { engine: ttsEngine, settings: ttsSettings } = useSentioTtsStore();
    const { sound } = useSentioBasicStore();
    const { chat, abort, chatting } = useChatWithAgent();
    const { startAudioTimer, stopAudioTimer } = useAudioTimer();
    const conversationIdRef = useRef<string>("");
    const handleStartRecord = () => {
        abort();
        if (micRecoder == null) {
            micRecoder = new Recorder({
                sampleBits: 16,         // é‡‡æ ·ä½æ•°ï¼Œæ”¯æŒ 8 æˆ– 16ï¼Œé»˜è®¤æ˜¯16
                sampleRate: 16000,      // é‡‡æ ·ç‡ï¼Œæ”¯æŒ 11025ã€16000ã€22050ã€24000ã€44100ã€48000
                numChannels: 1,         // å£°é“ï¼Œæ”¯æŒ 1 æˆ– 2ï¼Œ é»˜è®¤æ˜¯1
                compiling: false,
            })
        }
        micRecoder.start().then(
            () => {
                startAudioTimer();
                setStartMicRecord(true);
            }, () => {
                addToast({
                    title: t('micOpenError'),
                    variant: "flat",
                    color: "danger"
                })
            }
        )
    }
//åŸæœ‰å½•éŸ³é€»è¾‘
    // const handleStopRecord = async () => {
    //     micRecoder.stop();
    //     setStartMicRecord(false);
    //     if (!stopAudioTimer()) return;
    //     // å¼€å§‹åšè¯­éŸ³è¯†åˆ«
    //     setMessage(t('speech2text'));
    //     setStartAsrConvert(true);
    //     // è·å–mp3æ•°æ®, è½¬mp3çš„è®¡ç®—æ”¾åˆ°webå®¢æˆ·ç«¯, åç«¯æ‹¿åˆ°çš„æ˜¯mp3æ•°æ®
    //     const mp3Blob = convertToMp3(micRecoder);
    //     let asrResult = "";
    //     asrResult = await api_asr_infer_file(asrEngine, asrSettings, mp3Blob);
    //     if (asrResult.length > 0) {
    //         setMessage(asrResult);
    //     } else {
    //         setMessage("");
    //     }
    //     setStartAsrConvert(false);
    // }
    const handleStopRecord = async () => {
        try {
            // åœæ­¢å½•éŸ³
            micRecoder.stop();
            setStartMicRecord(false);
            
            if (!stopAudioTimer()) return;
            
            // å¼€å§‹åšè¯­éŸ³è¯†åˆ«
            setMessage(t('speech2text'));
            setStartAsrConvert(true);
            
            try {
                // è·å–mp3æ•°æ®
                const mp3Blob = convertToMp3(micRecoder);
                
                // é‡Šæ”¾éº¦å…‹é£èµ„æº
                micRecoder.destroy();
                micRecoder = null;
                
                // è¿›è¡Œè¯­éŸ³è¯†åˆ«
                const asrResult = await api_asr_infer_file(asrEngine, asrSettings, mp3Blob);
                
                if (asrResult.length > 0) {
                    setMessage(asrResult);
                } else {
                    setMessage("");
                }
            } catch (error) {
                console.error("Error during speech recognition:", error);
                setMessage("");
            } finally {
                setStartAsrConvert(false);
            }
        } catch (error) {
            console.error("Error stopping recording:", error);
            setStartMicRecord(false);
            setStartAsrConvert(false);
        }
    }


    const onFileClick = () => {
        // TODO: open file dialog
    }
    const onSendClick = async () => {
        if (message == "") return;
        
        // ä¿å­˜å½“å‰æ¶ˆæ¯å†…å®¹
        const currentMessage = message;
        
        // ç«‹å³æ¸…ç©ºè¾“å…¥æ¡†
        setMessage("");
        // console.log('ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯:', currentMessage);
        
        // ç«‹å³åœ¨UIä¸Šæ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯å’ŒAIç­‰å¾…çŠ¶æ€
        addChatRecord({ role: CHAT_ROLE.HUMAN, think: "", content: currentMessage });
        addChatRecord({ role: CHAT_ROLE.AI, think: "", content: "..." });
        
        // å¼‚æ­¥è·å–æˆªå›¾å¹¶å‘é€å®Œæ•´æ¶ˆæ¯ï¼ˆä¸å†é‡å¤æ·»åŠ UIæ¶ˆæ¯ï¼‰
        sendMessageWithScreenshot(currentMessage);
    }
    
    // å¼‚æ­¥è·å–æˆªå›¾å¹¶å‘é€å®Œæ•´æ¶ˆæ¯
    const sendMessageWithScreenshot = async (messageContent: string) => {
        let screenshotDataUrl: string | null = null;
        try {
            // ç­‰å¾…ä¸€ç§’ç¡®ä¿é¡µé¢æ¸²æŸ“å®Œæˆ
            await new Promise(resolve => setTimeout(resolve, 1000));
            
            // console.log('å¼€å§‹å¼‚æ­¥æˆªå–æ•´ä¸ªç½‘é¡µå†…å®¹...');
            screenshotDataUrl = await captureFullPageScreenshot();
            
            // å…¨é¡µé¢æˆªå›¾å‡½æ•°ï¼ˆé‡æ„ç‰ˆæœ¬ - é’ˆå¯¹index.htmlçˆ¶é¡µé¢æˆªå›¾ï¼‰
            async function captureFullPageScreenshot(): Promise<string> {
                // console.log('=== å¼€å§‹å…¨é¡µé¢æˆªå›¾ï¼ˆé’ˆå¯¹index.htmlçˆ¶é¡µé¢ï¼‰ ===');
                
                // æ£€æŸ¥æ˜¯å¦åœ¨iframeä¸­
                const isInIframe = window !== window.top;
                // console.log('æ˜¯å¦åœ¨iframeä¸­:', isInIframe);
                
                if (isInIframe) {
                    // åœ¨iframeä¸­ï¼Œéœ€è¦é€šè¿‡postMessageè¯·æ±‚çˆ¶é¡µé¢æˆªå›¾
                    // console.log('æ£€æµ‹åˆ°iframeç¯å¢ƒï¼Œå°†è¯·æ±‚çˆ¶é¡µé¢æ‰§è¡Œæˆªå›¾');
                    
                    return new Promise((resolve, reject) => {
                        // è®¾ç½®è¶…æ—¶å¤„ç†
                        const timeout = setTimeout(() => {
                            // console.error('çˆ¶é¡µé¢æˆªå›¾è¯·æ±‚è¶…æ—¶');
                            reject(new Error('çˆ¶é¡µé¢æˆªå›¾è¯·æ±‚è¶…æ—¶'));
                        }, 30000); // 30ç§’è¶…æ—¶
                        
                        // ç›‘å¬çˆ¶é¡µé¢çš„å›å¤
                        const messageHandler = (event: MessageEvent) => {
                            // console.log('æ”¶åˆ°çˆ¶é¡µé¢æ¶ˆæ¯:', event.data);
                            
                            if (event.data.type === 'SCREENSHOT_RESPONSE') {
                                clearTimeout(timeout);
                                window.removeEventListener('message', messageHandler);
                                
                                if (event.data.success) {
                                    // console.log('çˆ¶é¡µé¢æˆªå›¾æˆåŠŸï¼Œæ•°æ®å¤§å°:', Math.round(event.data.imageData.length / 1024), 'KB');
                                    resolve(event.data.imageData);
                                } else {
                                    // console.error('çˆ¶é¡µé¢æˆªå›¾å¤±è´¥:', event.data.error);
                                    reject(new Error(event.data.error || 'çˆ¶é¡µé¢æˆªå›¾å¤±è´¥'));
                                }
                            }
                        };
                        
                        window.addEventListener('message', messageHandler);
                        
                        // å‘é€æˆªå›¾è¯·æ±‚ç»™çˆ¶é¡µé¢
                        const request = {
                            type: 'SCREENSHOT_REQUEST',
                            timestamp: Date.now(),
                            source: 'digital-human-iframe'
                        };
                        
                        // console.log('å‘é€æˆªå›¾è¯·æ±‚ç»™çˆ¶é¡µé¢:', request);
                        window.parent.postMessage(request, '*');
                    });
                } else {
                    // ä¸åœ¨iframeä¸­ï¼Œç›´æ¥æˆªå–å½“å‰é¡µé¢
                    // console.log('ä¸åœ¨iframeä¸­ï¼Œç›´æ¥æˆªå–å½“å‰é¡µé¢');
                    return await captureCurrentPageDirectly();
                }
            }
            
            // ç›´æ¥æˆªå–å½“å‰é¡µé¢çš„å‡½æ•°
            async function captureCurrentPageDirectly(): Promise<string> {
                // console.log('å¼€å§‹ç›´æ¥æˆªå–å½“å‰é¡µé¢');
                
                const targetElement = document.documentElement || document.body;
                
                // è®¡ç®—å®Œæ•´çš„å°ºå¯¸
                const fullWidth = Math.max(
                    document.documentElement.scrollWidth,
                    document.documentElement.offsetWidth,
                    document.documentElement.clientWidth,
                    window.innerWidth
                );
                
                const fullHeight = Math.max(
                    document.documentElement.scrollHeight,
                    document.documentElement.offsetHeight,
                    document.documentElement.clientHeight,
                    window.innerHeight
                );
                
                // console.log('é¡µé¢å°ºå¯¸:', fullWidth, 'x', fullHeight);
                
                const canvasOptions: any = {
                    useCORS: true,
                    allowTaint: true,
                    backgroundColor: null,
                    scale: 1,
                    logging: true,
                    width: fullWidth,
                    height: fullHeight,
                    scrollX: 0,
                    scrollY: 0,
                    windowWidth: window.innerWidth,
                    windowHeight: window.innerHeight,
                    x: 0,
                    y: 0,
                    foreignObjectRendering: true,
                    removeContainer: false,
                    imageTimeout: 15000
                };
                
                try {
                    const canvas = await html2canvas(targetElement, canvasOptions);
                    // console.log('ç›´æ¥æˆªå›¾æˆåŠŸï¼Œå°ºå¯¸:', canvas.width, 'x', canvas.height);
                    return canvas.toDataURL('image/png', 1.0);
                } catch (error) {
                    // console.error('ç›´æ¥æˆªå›¾å¤±è´¥:', error);
                    throw error;
                }
            }
            
            // æˆªå›¾å®Œæˆï¼Œä¸€æ¬¡æ€§å‘é€å¸¦imageå­—æ®µçš„å®Œæ•´æ¶ˆæ¯
            // console.log('æˆªå›¾å®Œæˆï¼Œå‡†å¤‡å‘é€å¸¦æˆªå›¾çš„å®Œæ•´æ¶ˆæ¯');
            
        } catch (error) {
            // console.error('å¼‚æ­¥æˆªå›¾å¤±è´¥:', error);
            // console.log('æˆªå›¾å¤±è´¥ï¼Œå°†å‘é€ä¸å¸¦æˆªå›¾çš„æ¶ˆæ¯');
        }
        
        // æ— è®ºæˆªå›¾æˆåŠŸä¸å¦ï¼Œéƒ½å‘é€æ¶ˆæ¯ç»™åç«¯ï¼ˆå¸¦æˆ–ä¸å¸¦æˆªå›¾ï¼‰
        if (screenshotDataUrl) {
            // console.log('å‘é€å¸¦æˆªå›¾çš„å®Œæ•´æ¶ˆæ¯ç»™åç«¯ï¼Œæˆªå›¾å¤§å°:', Math.round(screenshotDataUrl.length / 1024), 'KB');
        } else {
            // console.log('å‘é€ä¸å¸¦æˆªå›¾çš„æ¶ˆæ¯ç»™åç«¯');
        }
        
        // å‘é€æ¶ˆæ¯+æˆªå›¾æ•°æ®ç»™åç«¯ï¼ˆæ³¨æ„ï¼šUIå·²ç»åœ¨onSendClickä¸­æ˜¾ç¤ºäº†ï¼‰
        sendMessageToBackend(messageContent, screenshotDataUrl);
    }
    
    // å‘é€æ¶ˆæ¯å’Œæˆªå›¾æ•°æ®åˆ°åç«¯ï¼ˆä¸é‡å¤æ·»åŠ UIæ¶ˆæ¯ï¼‰
    const sendMessageToBackend = (messageContent: string, screenshotData: string | null) => {
        // console.log('ğŸš€ å‘é€æ¶ˆæ¯åˆ°åç«¯ï¼ŒåŒ…å«æˆªå›¾æ•°æ®ï¼Œé¿å…é‡å¤UIæ˜¾ç¤º');
        // console.log('ğŸ“ æ¶ˆæ¯å†…å®¹:', messageContent);
        // console.log('ğŸ“· æˆªå›¾æ•°æ®:', screenshotData ? `å­˜åœ¨ï¼Œé•¿åº¦: ${screenshotData.length}` : 'æ— ');
        // console.log('ğŸ¤– Agentå¼•æ“:', agentEngine);
        // console.log('âš™ï¸ Agentè®¾ç½®:', agentSettings);
        // console.log('ğŸ’¬ ä¼šè¯ID:', conversationIdRef.current);
        
        // åˆ›å»ºAbortControllerç”¨äºå–æ¶ˆè¯·æ±‚
        const controller = new AbortController();
        
        // ç´¯ç§¯AIå›å¤å†…å®¹å’Œæ€è€ƒå†…å®¹
        let accumulatedResponse = "";
        let accumulatedThink = "";
        
        // TTSç›¸å…³çŠ¶æ€
        let ttsProcessIndex = 0;
        let agentDone = true;
        
        // æ ¹æ®æ–­å¥ç¬¦å·æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ–­å¥
        const findPuncIndex = (content: string, beginIndex: number) => {
            let latestIndex = -1;
            // æ‰¾æœ€è¿‘çš„æ–­å¥æ ‡ç‚¹ç¬¦å·
            for (let i = 0; i < SENTIO_TTS_PUNC.length; i++) {
                const index = content.indexOf(SENTIO_TTS_PUNC[i], beginIndex);
                if (index > beginIndex) {
                    if (latestIndex < 0 || index < latestIndex) {
                        latestIndex = index;
                    }
                }
            }
            return latestIndex;
        };
        
        // TTSå¤„ç†å‡½æ•°
        const doTTS = () => {
           // console.log('ğŸ”Š doTTS è¢«è°ƒç”¨, agentDone:', agentDone, 'ttsProcessIndex:', ttsProcessIndex, 'accumulatedResponseLength:', accumulatedResponse.length);
            if (!!!controller) {
                console.error('âŒ TTS æ§åˆ¶å™¨æœªåˆå§‹åŒ–');
                return;
            }
            // agentæŒç»­è¾“å‡ºä¸­ | agentResponseæœªå¤„ç†å®Œæ¯•
            if (!agentDone || accumulatedResponse.length > ttsProcessIndex) {
                let ttsText = "";
                const ttsCallback = (ttsResult: string) => {
                    //console.log('ğŸ”Š ttsCallback è¢«è°ƒç”¨, ç»“æœé•¿åº¦:', ttsResult?.length || 0);
                    if (ttsResult != "") {
                        try {
                            //console.log('ğŸ”Š å¼€å§‹å¤„ç†TTSç»“æœ, åŸå§‹æ•°æ®é•¿åº¦:', ttsResult.length);
                            const audioData = base64ToArrayBuffer(ttsResult);
                            //console.log('ğŸ”Š è½¬æ¢åçš„éŸ³é¢‘æ•°æ®å¤§å°:', audioData?.byteLength || 0);
                            
                            convertMp3ArrayBufferToWavArrayBuffer(audioData)
                                .then((buffer) => {
                                    //console.log('âœ… éŸ³é¢‘è½¬æ¢æˆåŠŸ, ç¼“å†²åŒºå¤§å°:', buffer?.byteLength || 0);
                                    try {
                                        const manager = Live2dManager.getInstance();
                                        console.log('ğŸ”Š Live2D Manager å®ä¾‹:', manager ? 'å·²åˆå§‹åŒ–' : 'æœªåˆå§‹åŒ–');
                                        if (manager) {
                                            manager.pushAudioQueue(buffer);
                                          //  console.log('âœ… éŸ³é¢‘å·²æ¨é€åˆ°æ’­æ”¾é˜Ÿåˆ—');
                                        } else {
                                            console.error('âŒ Live2D Manager æœªæ­£ç¡®åˆå§‹åŒ–');
                                        }
                                    } catch (e) {
                                        console.error('âŒ æ¨é€éŸ³é¢‘åˆ°é˜Ÿåˆ—æ—¶å‡ºé”™:', e);
                                    }
                                })
                                .catch(error => {
                                    console.error('âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥:', error);
                                });
                        } catch (e) {
                            console.error('âŒ å¤„ç†TTSç»“æœæ—¶å‡ºé”™:', e);
                        }
                    } else {
                        console.log('â„¹ï¸ ç©ºçš„TTSç»“æœï¼Œè·³è¿‡å¤„ç†');
                    }
                    // TTSå¤„ç†å®Œæ¯•ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–­å¥
                    doTTS();
                };

                let beginIndex = ttsProcessIndex;
                while (beginIndex >= ttsProcessIndex) {
                    const puncIndex = findPuncIndex(accumulatedResponse, beginIndex);
                    // æ‰¾åˆ°æ–­å¥
                    if (puncIndex > beginIndex) {
                        if (puncIndex - ttsProcessIndex > SENTIO_TTS_SENTENCE_LENGTH_MIN) {
                            ttsText = accumulatedResponse.substring(ttsProcessIndex, puncIndex + 1);
                            ttsProcessIndex = puncIndex + 1;
                            break;
                        } else {
                            // é•¿åº¦ä¸ç¬¦åˆ, ç»§ç»­å¾€åæ‰¾
                            beginIndex = puncIndex + 1;
                            continue;
                        }
                    }
                    // æœªæ‰¾åˆ°
                    beginIndex = -1;
                }
                if (ttsText.length == 0 && agentDone) {
                    // agentè¾“å‡ºå®Œæ¯•ï¼Œä½†æœªæ‰¾åˆ°æ–­å¥ç¬¦å·ï¼Œåˆ™å°†å‰©ä½™å†…å®¹å…¨éƒ¨è¿›è¡ŒTTS
                    ttsText = accumulatedResponse.substring(ttsProcessIndex);
                    ttsProcessIndex = accumulatedResponse.length;
                }
                if (ttsText != "") {
                    // å¤„ç†æ–­å¥tts
                    const processText = ttsTextPreprocess(ttsText);
                    if (!!processText) {
                        api_tts_infer(
                            ttsEngine, 
                            ttsSettings, 
                            processText, 
                            controller.signal
                        ).then((ttsResult) => {ttsCallback(ttsResult)});
                    } else {
                        ttsCallback("");
                    }
                } else {
                    // 10ms ä¼‘çœ å®šæ—¶å™¨æ‰§è¡Œ
                    setTimeout(() => {
                        doTTS();
                    }, 10);
                }
            }
        };
        
        // å®šä¹‰å›è°ƒå‡½æ•°å¤„ç†AIå“åº” - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œå»é™¤é¢„æœŸä¹‹å¤–çš„å†…å®¹å¹¶æ·»åŠ TTSæ”¯æŒ
        const agentCallback = (response: any) => {
           // console.log('âœ… æ”¶åˆ°AIå“åº”:', response);
          //  console.log('ğŸ“Š å“åº”äº‹ä»¶ç±»å‹:', response.event);
           // console.log('ğŸ“„ å“åº”æ•°æ®:', response.data);
            
            const event = response.event;
            const data = response.data;
            
            // åªå¤„ç†æœ‰æ•ˆçš„æ•°æ®å†…å®¹ï¼Œè¿‡æ»¤ç©ºå€¼å’Œæ— æ„ä¹‰å†…å®¹
            const isValidData = data && typeof data === 'string' && data.trim() !== '';
            
            // æ ¹æ®ä¸åŒçš„äº‹ä»¶ç±»å‹å¤„ç†
            switch (event) {
                case 'conversation_id':
                case 'CONVERSATION_ID':
                    // console.log('ğŸ†” ä¼šè¯ID:', data);
                    conversationIdRef.current = data;
                    break;
                    
                case 'message_id':
                case 'MESSAGE_ID':
                    // console.log('ğŸ“§ æ¶ˆæ¯ID:', data);
                    break;
                    
                case 'agent_thinking':
                case 'think':
                case 'THINK':
                    if (isValidData) {
                        // console.log('ğŸ¤” AIæ€è€ƒä¸­:', data);
                        accumulatedThink += data;
                        // åªæœ‰åœ¨æœ‰å®é™…å›å¤å†…å®¹æ—¶æ‰æ˜¾ç¤ºï¼Œé¿å…æ˜¾ç¤ºå ä½ç¬¦
                        const displayContent = accumulatedResponse || (accumulatedThink ? "æ€è€ƒä¸­..." : "");
                        updateLastRecord({ role: CHAT_ROLE.AI, think: accumulatedThink, content: displayContent });
                    }
                    break;
                    
                case 'agent_response':
                case 'text':
                case 'TEXT':
                    if (isValidData) {
                       // console.log('ğŸ’¬ æ”¶åˆ°AIå›å¤å†…å®¹ç‰‡æ®µ:', data);
                        accumulatedResponse += data;
                        updateLastRecord({ role: CHAT_ROLE.AI, think: accumulatedThink, content: accumulatedResponse });
                        
                        // è§¦å‘TTSè¯­éŸ³æ’­æŠ¥
                        if (agentDone && sound) {
                           // console.log('ğŸ”Š è§¦å‘TTSè¯­éŸ³æ’­æŠ¥ï¼ŒsoundçŠ¶æ€:', sound, 'agentDone:', agentDone);
                            agentDone = false;
                            doTTS();
                        } else {
                            console.log('ğŸ”‡ æœªè§¦å‘TTSï¼ŒåŸå› :', { sound, agentDone });
                        }
                    }
                    break;
                    
                case 'task':
                case 'TASK':
                case 'done':
                case 'DONE':
                    // console.log('âœ… AIå›å¤å®Œæˆï¼Œæœ€ç»ˆå†…å®¹:', accumulatedResponse);
                    // ç¡®ä¿æœ€ç»ˆå†…å®¹è¢«æ­£ç¡®æ˜¾ç¤ºï¼Œæ¸…é™¤æ€è€ƒå†…å®¹
                    if (accumulatedResponse && accumulatedResponse.trim() !== '') {
                        // console.log('ğŸ† æœ€ç»ˆå†…å®¹:', accumulatedResponse);
                        updateLastRecord({ role: CHAT_ROLE.AI, think: "", content: accumulatedResponse.trim() });
                    } else {
                        // å¦‚æœæ²¡æœ‰æœ‰æ•ˆå›å¤å†…å®¹ï¼Œæ˜¾ç¤ºé»˜è®¤æ¶ˆæ¯
                        updateLastRecord({ role: CHAT_ROLE.AI, think: "", content: 'æŠ±æ­‰ï¼Œæ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå›å¤ã€‚' });
                    }
                    
                    // å¤„ç†TTSç»“æŸé€»è¾‘
                    if (postProcess) {
                        postProcess(conversationIdRef.current, "", accumulatedThink, accumulatedResponse);
                    }
                    // æ ‡è®°agentè¾“å‡ºç»“æŸï¼Œè®©TTSå¤„ç†å‰©ä½™å†…å®¹
                    agentDone = true;
                    break;
                    
                case 'error':
                case 'ERROR':
                    // console.error('âŒ AIå“åº”é”™è¯¯:', data);
                    updateLastRecord({ role: CHAT_ROLE.AI, think: "", content: 'æŠ±æ­‰ï¼ŒAIå“åº”å‡ºç°é”™è¯¯ï¼Œè¯·é‡è¯•ã€‚' });
                    break;
                    
                default:
                    // å¯¹äºæœªçŸ¥äº‹ä»¶ç±»å‹ï¼Œåªè®°å½•æ—¥å¿—ï¼Œä¸å¤„ç†å†…å®¹ï¼Œé¿å…æ·»åŠ é¢„æœŸä¹‹å¤–çš„å†…å®¹
                    // console.log('â“ æœªçŸ¥äº‹ä»¶ç±»å‹ï¼Œå·²å¿½ç•¥:', event, 'æ•°æ®:', data);
                    break;
            }
        };
        
        // å®šä¹‰é”™è¯¯å›è°ƒå‡½æ•°å¤„ç†AIå“åº”é”™è¯¯
        const agentErrorCallback = (error: Error) => {
            // console.error('âŒ Agent APIé”™è¯¯:', error);
            // console.error('ğŸ” é”™è¯¯è¯¦æƒ…:', error.message);
            // console.error('ğŸ“‹ é”™è¯¯å †æ ˆ:', error.stack);
            updateLastRecord({ role: CHAT_ROLE.AI, think: "", content: 'æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ï¼Œè¯·é‡è¯•ã€‚' });
        };
        
        // console.log('ğŸ”„ å¼€å§‹è°ƒç”¨API...');
        // ç›´æ¥è°ƒç”¨APIï¼Œä¸é€šè¿‡chatå‡½æ•°ï¼ˆé¿å…é‡å¤æ·»åŠ UIæ¶ˆæ¯ï¼‰
        try {
            api_agent_stream(
                agentEngine,
                agentSettings,
                messageContent,
                conversationIdRef.current,
                controller.signal,
                agentCallback,
                agentErrorCallback,
                screenshotData
            );
            // console.log('âœ¨ APIè°ƒç”¨å·²å‘èµ·');
        } catch (error) {
            // console.error('ğŸ’¥ APIè°ƒç”¨å¤±è´¥:', error);
            updateLastRecord({ role: CHAT_ROLE.AI, think: "", content: 'æŠ±æ­‰ï¼ŒAPIè°ƒç”¨å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚' });
        }
    };
    
    const onKeyDown = (e: React.KeyboardEvent<HTMLInputElement>) => {
        // æ£€æŸ¥æ˜¯å¦æ˜¯ Enter é”®ï¼Œå¹¶ä¸”ä¸åœ¨è¾“å…¥æ³•ç»„åˆè¾“å…¥è¿‡ç¨‹ä¸­
        if (e.key === "Enter" && !e.nativeEvent.isComposing) {
            onSendClick();
        }
    }
    
    // ç”Ÿæˆå ä½å›¾ç‰‡å‡½æ•°
    const generatePlaceholderImage = () => {
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        canvas.width = 400;
        canvas.height = 300;
        
        // ç»˜åˆ¶é»‘è‰²èƒŒæ™¯
        ctx.fillStyle = '#000000';
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        
        // ç»˜åˆ¶ç™½è‰²æ–‡å­—
        ctx.fillStyle = '#ffffff';
        ctx.font = '20px Arial';
        ctx.textAlign = 'center';
        ctx.fillText('Live2D æ•°å­—äººæˆªå›¾', canvas.width / 2, canvas.height / 2 - 10);
        ctx.fillText('(æŠ€æœ¯é™åˆ¶ï¼Œæ˜¾ç¤ºå ä½å›¾)', canvas.width / 2, canvas.height / 2 + 20);
        
        return canvas.toDataURL('image/png');
    };
    
    // å¿«æ·é”®
    useEffect(() => {
        const handleKeyDown = (e: KeyboardEvent) => {
            if (e.key === "m" && e.ctrlKey) {
                if (startMicRecord) {
                    handleStopRecord();
                } else {
                    handleStartRecord();
                }
            }
        }
        window.addEventListener("keydown", handleKeyDown);
        return () => {
            window.removeEventListener("keydown", handleKeyDown);
        }
    })

    return (
        <div className='flex flex-col w-4/5 md:w-2/3 2xl:w-1/2 items-start z-10 gap-2'>
            <div className='flex w-full items-center z-10'>
                <Input
                    className='opacity-90'
                    startContent={
                        <button
                            type="button"
                            disabled={!enableASR}
                            aria-label="toggle password visibility"
                            className={clsx(
                                "focus:outline-none",
                                startMicRecord ? "text-red-500" : enableASR ? "hover:text-green-500" : "hover:text-gray-500"
                            )}
                        >
                            {startMicRecord ? (
                                <StopCircleIcon className='size-6' onClick={handleStopRecord} />
                            ) : (
                                startAsrConvert ? (
                                    <Spinner size="sm" />
                                ) : (
                                    <Tooltip className='opacity-90' content="Ctrl + M">
                                        <MicrophoneIcon className='size-6' onClick={handleStartRecord} />
                                    </Tooltip>
                                )
                            )}
                        </button>
                    }
                    endContent={
                        chatting ?
                            <button
                                type="button"
                                onClick={abort}
                                className="focus:outline-none hover:text-red-500"
                            >
                                <StopCircleIcon className='size-6' />
                            </button>
                            :
                            <></>
                        // <button
                        //     type="button"
                        //     onClick={onFileClick}
                        //     className="focus:outline-none hover:text-blue-500"
                        // >
                        //     <PaperClipIcon className='size-6 pointer-events-none' />
                        // </button>
                    }
                    type='text'
                    enterKeyHint='send'
                    value={message}
                    onValueChange={setMessage}
                    onKeyDown={onKeyDown}
                    disabled={startMicRecord || startAsrConvert}
                />
                <Button className='opacity-90' isIconOnly color="primary" onPress={onSendClick}>
                    <PaperAirplaneIcon className='size-6' />
                </Button>
            </div>
            
            {/* æˆªå›¾é¢„è§ˆæ¨¡æ€æ¡† */}
            <Modal 
                isOpen={showScreenshotPreview} 
                onClose={() => setShowScreenshotPreview(false)}
                size="2xl"
                scrollBehavior="inside"
            >
                <ModalContent>
                    <ModalHeader className="flex flex-col gap-1">
                        æˆªå›¾é¢„è§ˆ
                    </ModalHeader>
                    <ModalBody className="pb-6">
                        {screenshotDataUrl && (
                            <div className="bg-black rounded p-2">
                                <img 
                                    src={screenshotDataUrl} 
                                    alt="Live2Dæˆªå›¾" 
                                    className="w-full h-auto rounded"
                                    style={{ backgroundColor: '#000000' }}
                                />
                            </div>
                        )}
                    </ModalBody>
                </ModalContent>
            </Modal>
        </div>
    )
});

const convertFloat32ToAnalyseData = (float32Data: Float32Array) => {
    const analyseData = new Uint8Array(float32Data.length);
    const dataLength = float32Data.length;

    for (let i = 0; i < dataLength; i++) {
        const value = float32Data[i];
        // å°† -1 åˆ° 1 çš„å€¼æ˜ å°„åˆ° 0 åˆ° 255
        const mappedValue = Math.round((value + 1) * 128);
        // ç¡®ä¿å€¼åœ¨ 0 åˆ° 255 ä¹‹é—´
        analyseData[i] = Math.max(0, Math.min(255, mappedValue));
    }

    return analyseData;
}

export const ChatVadInput = memo(() => {
    const t = useTranslations('Products.sentio');
    const canvasRef = useRef<HTMLCanvasElement | null>(null)
    const ctxRef = useRef<CanvasRenderingContext2D | null>(null)
    const { engine: asrEngine, settings: asrSettings } = useSentioAsrStore();
    const { chat, abort } = useChatWithAgent();
    const { startAudioTimer, stopAudioTimer } = useAudioTimer();
    const waveData = useRef<Uint8Array | null>();
    const drawId = useRef<number | null>(null);

    const handleSpeechEnd = async (audio: Float32Array) => {
        // è·å–mp3æ•°æ®, è½¬mp3çš„è®¡ç®—æ”¾åˆ°webå®¢æˆ·ç«¯, åç«¯æ‹¿åˆ°çš„æ˜¯mp3æ•°æ®
        const mp3Blob = convertFloat32ArrayToMp3(audio);
        let asrResult = ""
        asrResult = await api_asr_infer_file(asrEngine, asrSettings, mp3Blob);
        if (asrResult.length > 0) {
            // ASRç»“æœç›´æ¥è°ƒç”¨chatï¼Œä¸è·³è¿‡UIæ›´æ–°ï¼ˆè¿™æ˜¯æ­£å¸¸çš„è¯­éŸ³è¾“å…¥æµç¨‹ï¼‰
            chat(asrResult);
        }
    }
    const vad = useMicVAD({
        baseAssetPath: getSrcPath("vad/"),
        onnxWASMBasePath: getSrcPath("vad/"),
        // model: "v5",
        onSpeechStart: () => {
            abort();
            startAudioTimer();
        },
        onFrameProcessed: (audio, frame) => {
            // frame è½¬ dataUnit8Array
            const dataUnit8Array = convertFloat32ToAnalyseData(frame);
            waveData.current = dataUnit8Array;
        },
        onSpeechEnd: (audio) => {
            if (stopAudioTimer()) {
                handleSpeechEnd(audio);
            }
        },
    });

    const initCanvas = () => {
        const dpr = window.devicePixelRatio || 1
        const canvas = document.getElementById('voice-input') as HTMLCanvasElement

        if (canvas) {
            const { width: cssWidth, height: cssHeight } = canvas.getBoundingClientRect()

            canvas.width = dpr * cssWidth
            canvas.height = dpr * cssHeight
            canvasRef.current = canvas

            const ctx = canvas.getContext('2d')
            if (ctx) {
                ctx.scale(dpr, dpr)
                ctx.fillStyle = 'rgb(215, 183, 237)'
                ctxRef.current = ctx
            }
        }
    }

    function drawCanvas() {
        const canvas = canvasRef.current!
        const ctx = ctxRef.current!
        if (canvas && ctx && waveData.current) {
            const resolution = 3
            const dataArray = [].slice.call(waveData.current)
            const lineLength = parseInt(`${canvas.width / resolution}`)
            const gap = parseInt(`${dataArray.length / lineLength}`)

            ctx.clearRect(0, 0, canvas.width, canvas.height)
            ctx.beginPath()
            let x = 0
            for (let i = 0; i < lineLength; i++) {
                let v = dataArray.slice(i * gap, i * gap + gap).reduce((prev: number, next: number) => {
                    return prev + next
                }, 0) / gap

                // if (v < 128)
                //     v = 128
                // if (v > 178)
                //     v = 178
                const y = (v - 128) / 128 * canvas.height

                ctx.moveTo(x, 16)
                if (ctx.roundRect)
                    ctx.roundRect(x, 16 - y, 2, y, [1, 1, 0, 0])
                else
                    ctx.rect(x, 16 - y, 2, y)
                ctx.fill()
                x += resolution
            }
            ctx.closePath();
        }
        drawId.current = requestAnimationFrame(drawCanvas);
    }

    useEffect(() => {
        initCanvas();
        drawId.current = requestAnimationFrame(drawCanvas);
        return () => {
            !!drawId.current && cancelAnimationFrame(drawId.current);
        }
    }, [])

    return (
        // <div>{vad.userSpeaking ? "User is speaking" : "no speaking"}</div>
        <div className='flex flex-col h-10 w-1/2 md:w-1/3 items-center'>
            {vad.loading && <div className='flex flex-row gap-1 items-center'>
                    <p className='text-xl font-bold'>{t('loading')}</p>
                    <Spinner color='warning' variant="dots" size='lg'/>
                </div>
            }
            <canvas id="voice-input" className='h-full w-full' />
        </div>
        
    )
});

export const ChatStreamInput = memo(() => {
    const t = useTranslations('Products.sentio');
    const canvasRef = useRef<HTMLCanvasElement | null>(null)
    const ctxRef = useRef<CanvasRenderingContext2D | null>(null)
    const { chat, abort } = useChatWithAgent();
    const { engine, settings } = useSentioAsrStore();
    const { getLastRecord, updateLastRecord, addChatRecord, deleteLastRecord } = useChatRecordStore();
    const waveData = useRef<Uint8Array | null>();
    const drawId = useRef<number | null>(null);
    const [engineLoading, setEngineLoading] = useState<boolean>(true);
    const engineReady = useRef<boolean>(false);

    const initCanvas = () => {
        const dpr = window.devicePixelRatio || 1
        const canvas = document.getElementById('voice-input') as HTMLCanvasElement

        if (canvas) {
            const { width: cssWidth, height: cssHeight } = canvas.getBoundingClientRect()

            canvas.width = dpr * cssWidth
            canvas.height = dpr * cssHeight
            canvasRef.current = canvas

            const ctx = canvas.getContext('2d')
            if (ctx) {
                ctx.scale(dpr, dpr)
                ctx.fillStyle = 'rgb(215, 183, 237)'
                ctxRef.current = ctx
            }
        }
    }

    function drawCanvas() {
        const canvas = canvasRef.current!
        const ctx = ctxRef.current!
        if (canvas && ctx && waveData.current) {
            const dataArray = [].slice.call(waveData.current)
            const resolution = 10
            const lineLength = parseInt(`${canvas.width / resolution}`)
            const gap = parseInt(`${dataArray.length / lineLength}`)
            ctx.clearRect(0, 0, canvas.width, canvas.height)
            ctx.beginPath()
            let x = 0
            for (let i = 0; i < lineLength; i++) {
                let v = dataArray.slice(i * gap, i * gap + gap).reduce((prev: number, next: number) => {
                    return prev + next
                }, 0) / gap

                // if (v < 128)
                //     v = 128
                // if (v > 178)
                //     v = 178
                const y = (v - 128) / 128 * canvas.height

                ctx.moveTo(x, 16)
                if (ctx.roundRect)
                    ctx.roundRect(x, 16 - y, 2, y, [1, 1, 0, 0])
                else
                    ctx.rect(x, 16 - y, 2, y)
                ctx.fill()
                x += resolution
            }
            ctx.closePath();
        }
        drawId.current = requestAnimationFrame(drawCanvas);
    }

    useEffect(() => {
        const asrWsClient = createASRWebsocketClient({
            engine: engine,
            config: settings,
            onMessage: (action: string, data: Uint8Array) => {
                const recvAction = action as WS_RECV_ACTION_TYPE;
                const recvData = new TextDecoder('utf-8').decode(data).trim();
                switch (recvAction) {
                    case WS_RECV_ACTION_TYPE.ENGINE_INITIALZING:
                        break;
                    case WS_RECV_ACTION_TYPE.ENGINE_STARTED:
                        setEngineLoading(false);
                        engineReady.current = true;
                        break;
                    case WS_RECV_ACTION_TYPE.ENGINE_PARTIAL_OUTPUT:
                        const lastChatRecord = getLastRecord();
                        if (lastChatRecord && lastChatRecord.role == CHAT_ROLE.AI) {
                            abort();
                            addChatRecord({ role: CHAT_ROLE.HUMAN, think: "", content: recvData })
                        } else {
                            updateLastRecord({ role: CHAT_ROLE.HUMAN, think: "", content: recvData })
                        }
                        break;
                    case WS_RECV_ACTION_TYPE.ENGINE_FINAL_OUTPUT:
                        deleteLastRecord();
                        // ä¼ å…¥skipUIUpdate: trueï¼Œé¿å…é‡å¤æ˜¾ç¤ºæ¶ˆæ¯ï¼ˆå› ä¸ºASRå·²ç»åœ¨PARTIAL_OUTPUTé˜¶æ®µæ˜¾ç¤ºäº†ç”¨æˆ·æ¶ˆæ¯ï¼‰
                        // console.log('ASRè¯­éŸ³è¯†åˆ«å®Œæˆï¼Œè°ƒç”¨chatå‡½æ•°ï¼Œè·³è¿‡UIæ›´æ–°é¿å…é‡å¤æ˜¾ç¤º');
                        chat(recvData, undefined, undefined, true);
                        break;
                    case WS_RECV_ACTION_TYPE.ENGINE_STOPPED:
                        setEngineLoading(true);
                        engineReady.current = false;
                        break;
                    case WS_RECV_ACTION_TYPE.ERROR:
                        setEngineLoading(true);
                        engineReady.current = false;
                        addToast({
                            title: recvData,
                            variant: "flat",
                            color: "danger"
                        })
                        break;
                    default:
                        break;
                }
            },
            onError: (error: Error) => {
                addToast({
                    title: error.message,
                    variant: "flat",
                    color: "danger"
                })
            }
        })
        const audioRecoder = new AudioRecoder(
            16000, 
            1, 
            16000 / 1000 * 60 * 2, // 60msæ•°æ®(å­—èŠ‚æ•°, ä¸€ä¸ªframe 16ä½, 2ä¸ªbyte)
            (chunk: Uint8Array) => {
                try {
                    if (asrWsClient.isConnected && engineReady.current) {
                        asrWsClient.sendMessage(WS_SEND_ACTION_TYPE.ENGINE_PARTIAL_INPUT, chunk) 
                    }
                } catch(error: any) {
                    addToast({
                        title: error.message,
                        variant: "flat",
                        color: "danger"
                    })
                }
            },
            (chunk: Float32Array) => {
                if (engineReady.current) {
                    waveData.current = convertFloat32ToAnalyseData(chunk);
                }
            }
        );
        initCanvas();
        drawId.current = requestAnimationFrame(drawCanvas);
        asrWsClient.connect();
        audioRecoder.start();

        return () => {
            audioRecoder.stop();
            asrWsClient.disconnect();
            !!drawId.current && cancelAnimationFrame(drawId.current);
        }
    }, [])

    return (
        <div className='flex flex-col h-10 w-1/2 md:w-1/3 items-center'>
            {engineLoading && <div className='flex flex-row gap-1 items-center'>
                    <p className='text-xl font-bold'>{t('loading')}</p>
                    <Spinner color='warning' variant="dots" size='lg'/>
                </div>
            }
            <canvas id="voice-input" className='h-full w-full' />
        </div>
        
    )
});